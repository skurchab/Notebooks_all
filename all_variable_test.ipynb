{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import glob\n",
    "from glob import glob\n",
    "import os\n",
    "import h2o\n",
    "from h2o.estimators.gbm import H2OGradientBoostingEstimator\n",
    "from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150423.csv\")\n",
    "d2=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150424.csv\")\n",
    "d3=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150425.csv\")\n",
    "d4=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150426.csv\")\n",
    "d5=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150427.csv\")\n",
    "d6=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150428.csv\")\n",
    "d7=pd.read_csv(\"/home/worldline/data/CSVagg/aggtrx_20150429.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d=[d1,d2,d3,d4,d5,d5,d6,d7]\n",
    "df=pd.concat(d, ignore_index=True)\n",
    "del df['TX_ACCEPTED']\n",
    "del df['MIN_AMT_LAST_24H']\n",
    "df_f1=df[df.TX_FRAUD==1]\n",
    "df_f0=df[df.TX_FRAUD==0]\n",
    "df_f0_s=df_f0.sample(len(df[df.TX_FRAUD==1]))\n",
    "df_s=pd.concat([df_f0_s,df_f1],ignore_index=True)\n",
    "df_s.to_csv(\"select/train_all\", index=False, header=True)\n",
    "#df_s.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'/home/worldline/data/CSVagg'\n",
    "filenames =sorted(glob(path + \"/*.csv\"))\n",
    "filenames_te=filenames[filenames.index(path+'/aggtrx_20150508.csv'):(filenames.index(path+'/aggtrx_20150531.csv')+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#path = r'/home/worldline/data/CSVagg'\n",
    "#filenames =sorted(glob(path + \"/*.csv\"))\n",
    "#filenames_te1=filenames[filenames.index(path+\"/aggtrx_20150314.csv\"):(filenames.index(path+\"/aggtrx_20150321.csv\")+1)]\n",
    "#filenames_te2=filenames[filenames.index(path+\"/aggtrx_20150322.csv\"):(filenames.index(path+\"/aggtrx_20150329.csv\")+1)]\n",
    "#filenames_te3=filenames[filenames.index(path+\"/aggtrx_20150330.csv\"):(filenames.index(path+\"/aggtrx_20150406.csv\")+1)]\n",
    "#filenames_te4=filenames[filenames.index(path+\"/aggtrx_20150407.csv\"):(filenames.index(path+\"/aggtrx_20150414.csv\")+1)]\n",
    "#filenames_te5=filenames[filenames.index(path+\"/aggtrx_20150415.csv\"):(filenames.index(path+\"/aggtrx_20150422.csv\")+1)]\n",
    "#filenames_te6=filenames[filenames.index(path+\"/aggtrx_20150423.csv\"):(filenames.index(path+\"/aggtrx_20150430.csv\")+1)]\n",
    "#filenames_te7=filenames[filenames.index(path+\"/aggtrx_20150501.csv\"):(filenames.index(path+\"/aggtrx_20150508.csv\")+1)]\n",
    "#filenames_te8=filenames[filenames.index(path+\"/aggtrx_20150509.csv\"):(filenames.index(path+\"/aggtrx_20150516.csv\")+1)]\n",
    "#filenames_te9=filenames[filenames.index(path+\"/aggtrx_20150516.csv\"):(filenames.index(path+\"/aggtrx_20150523.csv\")+1)]\n",
    "#filenames_te10=filenames[filenames.index(path+\"/aggtrx_20150524.csv\"):(filenames.index(path+\"/aggtrx_20150531.csv\")+1)]\n",
    "#filenames_te=[filenames_te1,filenames_te2,filenames_te3,filenames_te4,filenames_te5,filenames_te6,filenames_te7,filenames_te8,filenames_te9,filenames_te10]\n",
    "#h2o.init(port=54331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h2o.init(port=54331)\n",
    "\n",
    "train_col=['TX_AMOUNT','AGE','TX_TIME_SECONDS','NB_TRX_LAST_24H','TERM_MIDUID','TERM_MCC','TERM_COUNTRY','TX_3D_SECURE',\n",
    "           'LANGUAGE','GENDER','BROKER','CARD_BRAND','TX_TIME_HOURS','TX_TIME_DAYS','TERM_REGION','TERM_CONTINENT',\n",
    "           'TERM_MCCG','TERM_MCC_GROUP','SUM_AMT_LAST_24H','TX_DIFF_LAST_TX','LAST_MIDUID_TX','LAST_COUNTRY_TX','LAST_MCC_HIS']\n",
    "resp_col='TX_FRAUD'\n",
    "df_f0_s=df_f0.sample(len(df[df.TX_FRAUD==1]))\n",
    "df_s=pd.concat([df_f0_s,df_f1],ignore_index=True)\n",
    "df_s.to_csv(\"select/train_all\", index=False, header=True)\n",
    "df_train = h2o.import_file(\"select/train_all\")\n",
    "model1 = H2ORandomForestEstimator(ntrees=10, max_depth=15, nfolds=10, binomial_double_trees=True, stopping_metric= \"auc\", keep_cross_validation_predictions = True,\n",
    "                                  seed=1)\n",
    "model1.train(x=train_col, y=resp_col, training_frame=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_f0_s=df_f0.sample(len(df[df.TX_FRAUD==1]))\n",
    "df_s=pd.concat([df_f0_s,df_f1],ignore_index=True)\n",
    "df_s.to_csv(\"select/train_all\", index=False, header=True)\n",
    "df_train = h2o.import_file(\"select/train_all\")\n",
    "model2 = H2ORandomForestEstimator(ntrees=10, max_depth=15, nfolds=10, binomial_double_trees=True, stopping_metric= \"auc\", keep_cross_validation_predictions = True,\n",
    "                                  seed=1)\n",
    "model2.train(x=train_col, y=resp_col, training_frame=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n",
    "ensemble = H2OStackedEnsembleEstimator(base_models=[model1, model2])\n",
    "ensemble.train(x=train_col, y=resp_col, training_frame=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Ensemble\n",
    "ROC_AUC=[]\n",
    "Average_Precision=[]\n",
    "Share=[]\n",
    "Fraud_ID=[]\n",
    "#h2o.init(port=54331)\n",
    "#df_train = h2o.import_file(\"select/train_all\")\n",
    "#train_col=['TX_AMOUNT','AGE','TX_TIME_SECONDS','NB_TRX_LAST_24H','TERM_MIDUID','TERM_MCC','TERM_COUNTRY','TX_3D_SECURE',\n",
    "#           'LANGUAGE','GENDER','BROKER','CARD_BRAND','TX_TIME_HOURS','TX_TIME_DAYS','TERM_REGION','TERM_CONTINENT',\n",
    "#           'TERM_MCCG','TERM_MCC_GROUP','SUM_AMT_LAST_24H','TX_DIFF_LAST_TX','LAST_MIDUID_TX','LAST_COUNTRY_TX','LAST_MCC_HIS']\n",
    "#resp_col='TX_FRAUD'\n",
    "#model = H2ORandomForestEstimator(ntrees=10, max_depth=15, nfolds=10, binomial_double_trees=True, stopping_metric= \"auc\")\n",
    "#model.train(x=train_col, y=resp_col, training_frame=df_train)\n",
    "for f in filenames_te:\n",
    "    data=pd.read_csv(f)\n",
    "    data.TX_FRAUD.apply(str)\n",
    "    del data['TX_ACCEPTED']\n",
    "    del data['MIN_AMT_LAST_24H']\n",
    "    data=data[~ data.CARD_PAN_ID.isin(Fraud_ID)]\n",
    "    specname = f.split(\"/\")[-1]\n",
    "    data.to_csv(os.path.join('select/%s'% specname))\n",
    "    df_val=h2o.import_file(os.path.join('select/%s'% specname))\n",
    "    pred=ensemble.predict(df_val)\n",
    "    pr=h2o.h2o.as_list(pred, use_pandas=True)\n",
    "    tr=h2o.h2o.as_list(df_val, use_pandas=True)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(tr.TX_FRAUD,pr.predict,pos_label=1)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    ROC_AUC.append(roc_auc)\n",
    "    precision, recall, thresholds=precision_recall_curve(tr.TX_FRAUD,pr.predict,pos_label=1)\n",
    "    average_precision=average_precision_score(tr.TX_FRAUD, pr.predict)\n",
    "    Average_Precision.append(average_precision)\n",
    "    gr=(pd.concat([tr.CARD_PAN_ID,pr.predict,tr.TX_FRAUD],axis=1)).groupby(\"CARD_PAN_ID\").max().sort_values(\"predict\",ascending=False)\n",
    "    per=((gr.head(100))[(gr.head(100)).TX_FRAUD==1].count()).TX_FRAUD\n",
    "    Share.append(per)\n",
    "    frauds=(gr.head(100))[(gr.head(100)).TX_FRAUD==1].index.tolist()\n",
    "    Fraud_ID=Fraud_ID+list((gr.head(100))[(gr.head(100)).TX_FRAUD==1].index.unique())\n",
    "Final_table=pd.DataFrame({\"ROC_AUC\": ROC_AUC,\n",
    "                          \"Average_Precision\": Average_Precision,\n",
    "                          \"Share\": Share})\n",
    "A_P_m=Final_table.Average_Precision.mean()\n",
    "AUC_m=Final_table.ROC_AUC.mean()\n",
    "share_m=Final_table.Share.mean()\n",
    "print(\"Average precision mean: {}, ROC AUC mean: {}, Share of fraudulant card in top 100 mean: {}\".format(A_P_m, AUC_m, share_m))\n",
    "h2o.cluster().shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Final_table.Average_Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Final_table.ROC_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Final_table.Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Main (one forest)\n",
    "ROC_AUC=[]\n",
    "Average_Precision=[]\n",
    "Share=[]\n",
    "Fraud_ID=[]\n",
    "h2o.init(port=54331)\n",
    "df_train = h2o.import_file(\"select/train_all\")\n",
    "train_col=['TX_AMOUNT','AGE','TX_TIME_SECONDS','NB_TRX_LAST_24H','TERM_MIDUID','TERM_MCC','TERM_COUNTRY','TX_3D_SECURE',\n",
    "           'LANGUAGE','GENDER','BROKER','CARD_BRAND','TX_TIME_HOURS','TX_TIME_DAYS','TERM_REGION','TERM_CONTINENT',\n",
    "           'TERM_MCCG','TERM_MCC_GROUP','SUM_AMT_LAST_24H','TX_DIFF_LAST_TX','LAST_MIDUID_TX','LAST_COUNTRY_TX','LAST_MCC_HIS']\n",
    "resp_col='TX_FRAUD'\n",
    "model = H2ORandomForestEstimator(ntrees=10, max_depth=15, nfolds=10, binomial_double_trees=True, stopping_metric= \"auc\")\n",
    "model.train(x=train_col, y=resp_col, training_frame=df_train)\n",
    "for f in filenames_te:\n",
    "    data=pd.read_csv(f)\n",
    "    data.TX_FRAUD.apply(str)\n",
    "    del data['TX_ACCEPTED']\n",
    "    del data['MIN_AMT_LAST_24H']\n",
    "    data=data[~ data.CARD_PAN_ID.isin(Fraud_ID)]\n",
    "    specname = f.split(\"/\")[-1]\n",
    "    data.to_csv(os.path.join('select/%s'% specname))\n",
    "    df_val=h2o.import_file(os.path.join('select/%s'% specname))\n",
    "    pred=model.predict(df_val)\n",
    "    pr=h2o.h2o.as_list(pred, use_pandas=True)\n",
    "    tr=h2o.h2o.as_list(df_val, use_pandas=True)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(tr.TX_FRAUD,pr.predict,pos_label=1)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    ROC_AUC.append(roc_auc)\n",
    "    precision, recall, thresholds=precision_recall_curve(tr.TX_FRAUD,pr.predict,pos_label=1)\n",
    "    average_precision=average_precision_score(tr.TX_FRAUD, pr.predict)\n",
    "    Average_Precision.append(average_precision)\n",
    "    gr=(pd.concat([tr.CARD_PAN_ID,pr.predict,tr.TX_FRAUD],axis=1)).groupby(\"CARD_PAN_ID\").max().sort_values(\"predict\",ascending=False)\n",
    "    per=((gr.head(100))[(gr.head(100)).TX_FRAUD==1].count()).TX_FRAUD\n",
    "    Share.append(per)\n",
    "    frauds=(gr.head(100))[(gr.head(100)).TX_FRAUD==1].index.tolist()\n",
    "    Fraud_ID=Fraud_ID+list((gr.head(100))[(gr.head(100)).TX_FRAUD==1].index.unique())\n",
    "Final_table=pd.DataFrame({\"ROC_AUC\": ROC_AUC,\n",
    "                          \"Average_Precision\": Average_Precision,\n",
    "                          \"Share\": Share})\n",
    "A_P_m=Final_table.Average_Precision.mean()\n",
    "AUC_m=Final_table.ROC_AUC.mean()\n",
    "share_m=Final_table.Share.mean()\n",
    "print(\"Average precision mean: {}, ROC AUC mean: {}, Share of fraudulant card in top 100 mean: {}\".format(A_P_m, AUC_m, share_m))\n",
    "h2o.cluster().shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Main with average\n",
    "h2o.init(port=54331)\n",
    "ROC_AUC=[]\n",
    "Average_Precision=[]\n",
    "Share=[]\n",
    "Fraud_ID=[]\n",
    "#df_train = h2o.import_file(\"select/train_all\")\n",
    "train_col=['TX_AMOUNT','AGE','TX_TIME_SECONDS','NB_TRX_LAST_24H','TERM_MIDUID','TERM_MCC','TERM_COUNTRY','TX_3D_SECURE',\n",
    "           'LANGUAGE','GENDER','BROKER','CARD_BRAND','TX_TIME_HOURS','TX_TIME_DAYS','TERM_REGION','TERM_CONTINENT',\n",
    "           'TERM_MCCG','TERM_MCC_GROUP','SUM_AMT_LAST_24H','TX_DIFF_LAST_TX','LAST_MIDUID_TX','LAST_COUNTRY_TX','LAST_MCC_HIS']\n",
    "resp_col='TX_FRAUD'\n",
    "model = H2ORandomForestEstimator(ntrees=10, max_depth=15, nfolds=10, binomial_double_trees=True, \n",
    "                                 stopping_metric= \"auc\", keep_cross_validation_predictions = True,\n",
    "                                 seed=1)\n",
    "ite=3\n",
    "for f in filenames_te:\n",
    "    data=pd.read_csv(f)\n",
    "    data.TX_FRAUD.apply(str)\n",
    "    del data['TX_ACCEPTED']\n",
    "    del data['MIN_AMT_LAST_24H']\n",
    "    data=data[~ data.CARD_PAN_ID.isin(Fraud_ID)]\n",
    "    specname = f.split(\"/\")[-1]\n",
    "    data.to_csv(os.path.join('select/%s'% specname))\n",
    "    df_val=h2o.import_file(os.path.join('select/%s'% specname))\n",
    "    dct = {}\n",
    "    for i in range (ite):\n",
    "        df_f0_s=df_f0.sample(len(df[df.TX_FRAUD==1]))\n",
    "        df_s=pd.concat([df_f0_s,df_f1],ignore_index=True)\n",
    "        #del df_s['TX_ACCEPTED']\n",
    "        #del df_s['MIN_AMT_LAST_24H']\n",
    "        df_s.to_csv(\"select/train_all\", index=False, header=True)\n",
    "        df_train = h2o.import_file(\"select/train_all\")\n",
    "        model.train(x=train_col, y=resp_col, training_frame=df_train)\n",
    "        dct['pred_%s' % i]=h2o.h2o.as_list(model.predict(df_val), use_pandas=True)\n",
    "    p=sum(dct.values())\n",
    "    pe=pd.DataFrame(p)\n",
    "    pe.predict=pe.predict.div(ite)\n",
    "    #pred=[]\n",
    "    #for i in pe.predict:\n",
    "      #  k=i/3\n",
    "    #    pred.append(k)\n",
    "    #pred=pd.DataFrame(pred)\n",
    "    #pred[\"predict\"]=pred[0]\n",
    "    tr=h2o.h2o.as_list(df_val, use_pandas=True)\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(tr.TX_FRAUD,pe.predict,pos_label=1)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "    ROC_AUC.append(roc_auc)\n",
    "    precision, recall, thresholds=precision_recall_curve(tr.TX_FRAUD,pe.predict,pos_label=1)\n",
    "    average_precision=average_precision_score(tr.TX_FRAUD, pe.predict)\n",
    "    Average_Precision.append(average_precision)\n",
    "    gr=(pd.concat([tr.CARD_PAN_ID,pe.predict,tr.TX_FRAUD],axis=1)).groupby(\"CARD_PAN_ID\").max().sort_values(\"predict\",ascending=False)\n",
    "    #top=gr.head(100)\n",
    "    per=((gr.head(100))[(gr.head(100)).TX_FRAUD==1].count()).TX_FRAUD\n",
    "    Share.append(per)\n",
    "    frauds=(gr.head(100))[(gr.head(100)).TX_FRAUD==1].index.tolist()\n",
    "    Fraud_ID=Fraud_ID+list((gr.head(100))[(gr.head(100)).TX_FRAUD==1].index.unique())\n",
    "Final_table=pd.DataFrame({\"ROC_AUC\": ROC_AUC,\n",
    "                          \"Average_Precision\": Average_Precision,\n",
    "                          \"Share\": Share})\n",
    "A_P_m=Final_table.Average_Precision.mean()\n",
    "AUC_m=Final_table.ROC_AUC.mean()\n",
    "share_m=Final_table.Share.mean()\n",
    "print(\"Average precision mean: {}, ROC AUC mean: {}, Share of fraudulant card in top 100 mean: {}\".format(A_P_m, AUC_m, share_m))\n",
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Final_table.Average_Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Final_table.ROC_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(Final_table.Share)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Main all variables\n",
    "ROC_AUC=[]\n",
    "Average_Precision=[]\n",
    "Share=[]\n",
    "Fraud_ID=[]\n",
    "for file in filenames_te:\n",
    "    for f in file:\n",
    "        h2o.cluster().shutdown()\n",
    "        data=pd.read_csv(f)\n",
    "        data.TX_FRAUD.apply(str)\n",
    "        del data['TX_ACCEPTED']\n",
    "        data=data[~ data.CARD_PAN_ID.isin(Fraud_ID)]\n",
    "        specname = f.split(\"/\")[-1]\n",
    "        data.to_csv(os.path.join('select/%s'% specname))\n",
    "        h2o.init(port=54331)\n",
    "        df_train = h2o.import_file(\"select/train_all\")\n",
    "        df_val=h2o.import_file(os.path.join('select/%s'% specname))\n",
    "        train_col=['TX_AMOUNT','AGE','TX_TIME_SECONDS','NB_TRX_LAST_24H','TERM_MIDUID','TERM_MCC','TERM_COUNTRY','TX_3D_SECURE',\n",
    "                  'LANGUAGE','GENDER','BROKER','CARD_BRAND','TX_TIME_HOURS','TX_TIME_DAYS','TERM_REGION','TERM_CONTINENT','TERM_MCCG','TERM_MCC_GROUP',\n",
    "                  'SUM_AMT_LAST_24H','TX_DIFF_LAST_TX','LAST_MIDUID_TX','LAST_COUNTRY_TX','LAST_MCC_HIS']\n",
    "        resp_col='TX_FRAUD'\n",
    "        model = H2ORandomForestEstimator(ntrees=10, max_depth=15, nfolds=10, binomial_double_trees=True, stopping_metric= \"auc\")\n",
    "        model.train(x=train_col, y=resp_col, training_frame=df_train)\n",
    "        pred=model.predict(df_val)\n",
    "        pr=h2o.h2o.as_list(pred, use_pandas=True)\n",
    "        tr=h2o.h2o.as_list(df_val, use_pandas=True)\n",
    "        false_positive_rate, true_positive_rate, thresholds = roc_curve(tr.TX_FRAUD,pr.predict,pos_label=1)\n",
    "        roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "        ROC_AUC.append(roc_auc)\n",
    "        precision, recall, thresholds=precision_recall_curve(tr.TX_FRAUD,pr.predict,pos_label=1)\n",
    "        average_precision=average_precision_score(tr.TX_FRAUD, pr.predict) \n",
    "        Average_Precision.append(average_precision)\n",
    "        n=[tr.CARD_PAN_ID,pr.predict,tr.TX_FRAUD]\n",
    "        new=pd.concat(n,axis=1)\n",
    "        gr=new.groupby(\"CARD_PAN_ID\").max().sort_values(\"predict\",ascending=False)\n",
    "        top=gr.head(100)\n",
    "        per=(top[top.TX_FRAUD==1].count())/100\n",
    "        perc=per.TX_FRAUD # frauds in top 100\n",
    "        Share.append(perc)\n",
    "        frauds=top[top.TX_FRAUD==1].index.tolist()\n",
    "        Fraud_ID=Fraud_ID+list(top[top.TX_FRAUD==1].index.unique())\n",
    "    print('The {} is done!'.format(file))\n",
    "    Final_table=pd.DataFrame({\"ROC_AUC\": ROC_AUC,\n",
    "                              \"Average_Precision\": Average_Precision,\n",
    "                              \"Share\": Share})\n",
    "A_P_m=Final_table.Average_Precision.mean()\n",
    "AUC_m=Final_table.ROC_AUC.mean()\n",
    "share_m=Final_table.Share.mean()\n",
    "print(\"Average precision mean: {}, ROC AUC mean: {}, Share of fraudulant card in top 100 mean: {}\".format(A_P_m, AUC_m, share_m))\n",
    "Final_table\n",
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
